{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DATALOADDER_CNN.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMZYf/+qqNO/PvO8ycdp5Py",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zrghassabi/Convolutional-Neural-Network/blob/main/DATALOADDER_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhUwdJriODBe"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOz9pM3sllCd",
        "outputId": "af8f19a6-7ae0-403a-ebe7-262b78a82cdb"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "\n",
        "print(torch.version)\n",
        "print(torch.cuda.get_device_name())\n",
        "print(torch.cuda.get_device_properties('cuda'))"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<module 'torch.version' from '/usr/local/lib/python3.7/dist-packages/torch/version.py'>\n",
            "Tesla K80\n",
            "_CudaDeviceProperties(name='Tesla K80', major=3, minor=7, total_memory=11441MB, multi_processor_count=13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1GNLtkslfkb"
      },
      "source": [
        "# Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkUBARDllonD"
      },
      "source": [
        "Batch_size=256\n",
        "num_class=10\n",
        "device='cuda' if torch.cuda.is_available() else'cpu)'"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V21Il5Vguruh"
      },
      "source": [
        "#Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJbZJC86uxR3"
      },
      "source": [
        "train_dataset=MNIST('./MNIST', train= True, transform= transforms.ToTensor(),download= True)\n",
        "\n",
        "test_dataset=MNIST('./MNIST', train= False, transform= transforms.ToTensor(),download= True)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ta5lrzvNzgoe"
      },
      "source": [
        "train_loader=torch.utils.data.DataLoader(dataset=train_dataset,batch_size=Batch_size,  shuffle=True, drop_last=True)\n",
        "\n",
        "test_loader=torch.utils.data.DataLoader(dataset=test_dataset,batch_size=Batch_size, shuffle=True)\n"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peST4jwN24oF",
        "outputId": "adafd268-cc3e-461e-8a12-5ca5279b0816"
      },
      "source": [
        "#In case you want to see one batch\n",
        "one_train_batch_imgs, one_train_batch_lbls=next(iter(train_loader))\n",
        "print(one_train_batch_imgs.shape)\n",
        "print(one_train_batch_lbls)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([256, 1, 28, 28])\n",
            "tensor([4, 1, 8, 5, 5, 8, 3, 7, 2, 2, 3, 2, 8, 2, 4, 8, 5, 1, 4, 9, 7, 9, 4, 6,\n",
            "        1, 7, 0, 1, 8, 3, 4, 7, 5, 2, 5, 7, 6, 1, 5, 5, 2, 0, 0, 6, 1, 6, 7, 5,\n",
            "        7, 8, 7, 3, 3, 4, 3, 6, 6, 2, 3, 3, 2, 6, 4, 5, 6, 2, 8, 7, 8, 3, 9, 2,\n",
            "        1, 6, 3, 8, 5, 8, 9, 8, 4, 9, 4, 7, 0, 0, 5, 4, 8, 9, 2, 9, 2, 0, 4, 7,\n",
            "        1, 9, 9, 9, 3, 8, 5, 2, 3, 6, 1, 2, 6, 6, 9, 9, 8, 2, 8, 7, 9, 9, 9, 7,\n",
            "        5, 2, 3, 9, 8, 6, 4, 2, 0, 9, 6, 6, 9, 6, 1, 2, 8, 8, 0, 7, 5, 8, 2, 2,\n",
            "        6, 0, 9, 4, 0, 8, 1, 0, 7, 6, 7, 4, 7, 4, 6, 2, 6, 2, 9, 8, 2, 0, 8, 7,\n",
            "        9, 3, 7, 0, 0, 8, 3, 0, 1, 8, 8, 9, 4, 8, 9, 5, 1, 7, 4, 6, 2, 6, 6, 2,\n",
            "        0, 7, 7, 2, 3, 7, 9, 0, 2, 3, 0, 3, 2, 9, 7, 7, 0, 3, 0, 8, 6, 3, 4, 8,\n",
            "        5, 8, 0, 2, 0, 9, 6, 0, 4, 7, 7, 4, 5, 9, 2, 6, 7, 2, 7, 6, 5, 2, 4, 3,\n",
            "        8, 1, 9, 4, 4, 5, 7, 0, 4, 5, 7, 3, 7, 4, 3, 6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X086LJIM4G_0"
      },
      "source": [
        ""
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcjlxfm60dBJ",
        "outputId": "9c70bd84-19dc-43cb-8306-92e4bc05f579"
      },
      "source": [
        "for batch_number, (images, labels) in enumerate(train_loader):  #enumerate shows the num of batches\n",
        "    print(batch_number,images.shape)                            # each image has 1 channel, batch size is 256, size of image is 28*28\n",
        "                                                                #drop_last=True in loader  discard last batch which its size is 96"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 torch.Size([256, 1, 28, 28])\n",
            "1 torch.Size([256, 1, 28, 28])\n",
            "2 torch.Size([256, 1, 28, 28])\n",
            "3 torch.Size([256, 1, 28, 28])\n",
            "4 torch.Size([256, 1, 28, 28])\n",
            "5 torch.Size([256, 1, 28, 28])\n",
            "6 torch.Size([256, 1, 28, 28])\n",
            "7 torch.Size([256, 1, 28, 28])\n",
            "8 torch.Size([256, 1, 28, 28])\n",
            "9 torch.Size([256, 1, 28, 28])\n",
            "10 torch.Size([256, 1, 28, 28])\n",
            "11 torch.Size([256, 1, 28, 28])\n",
            "12 torch.Size([256, 1, 28, 28])\n",
            "13 torch.Size([256, 1, 28, 28])\n",
            "14 torch.Size([256, 1, 28, 28])\n",
            "15 torch.Size([256, 1, 28, 28])\n",
            "16 torch.Size([256, 1, 28, 28])\n",
            "17 torch.Size([256, 1, 28, 28])\n",
            "18 torch.Size([256, 1, 28, 28])\n",
            "19 torch.Size([256, 1, 28, 28])\n",
            "20 torch.Size([256, 1, 28, 28])\n",
            "21 torch.Size([256, 1, 28, 28])\n",
            "22 torch.Size([256, 1, 28, 28])\n",
            "23 torch.Size([256, 1, 28, 28])\n",
            "24 torch.Size([256, 1, 28, 28])\n",
            "25 torch.Size([256, 1, 28, 28])\n",
            "26 torch.Size([256, 1, 28, 28])\n",
            "27 torch.Size([256, 1, 28, 28])\n",
            "28 torch.Size([256, 1, 28, 28])\n",
            "29 torch.Size([256, 1, 28, 28])\n",
            "30 torch.Size([256, 1, 28, 28])\n",
            "31 torch.Size([256, 1, 28, 28])\n",
            "32 torch.Size([256, 1, 28, 28])\n",
            "33 torch.Size([256, 1, 28, 28])\n",
            "34 torch.Size([256, 1, 28, 28])\n",
            "35 torch.Size([256, 1, 28, 28])\n",
            "36 torch.Size([256, 1, 28, 28])\n",
            "37 torch.Size([256, 1, 28, 28])\n",
            "38 torch.Size([256, 1, 28, 28])\n",
            "39 torch.Size([256, 1, 28, 28])\n",
            "40 torch.Size([256, 1, 28, 28])\n",
            "41 torch.Size([256, 1, 28, 28])\n",
            "42 torch.Size([256, 1, 28, 28])\n",
            "43 torch.Size([256, 1, 28, 28])\n",
            "44 torch.Size([256, 1, 28, 28])\n",
            "45 torch.Size([256, 1, 28, 28])\n",
            "46 torch.Size([256, 1, 28, 28])\n",
            "47 torch.Size([256, 1, 28, 28])\n",
            "48 torch.Size([256, 1, 28, 28])\n",
            "49 torch.Size([256, 1, 28, 28])\n",
            "50 torch.Size([256, 1, 28, 28])\n",
            "51 torch.Size([256, 1, 28, 28])\n",
            "52 torch.Size([256, 1, 28, 28])\n",
            "53 torch.Size([256, 1, 28, 28])\n",
            "54 torch.Size([256, 1, 28, 28])\n",
            "55 torch.Size([256, 1, 28, 28])\n",
            "56 torch.Size([256, 1, 28, 28])\n",
            "57 torch.Size([256, 1, 28, 28])\n",
            "58 torch.Size([256, 1, 28, 28])\n",
            "59 torch.Size([256, 1, 28, 28])\n",
            "60 torch.Size([256, 1, 28, 28])\n",
            "61 torch.Size([256, 1, 28, 28])\n",
            "62 torch.Size([256, 1, 28, 28])\n",
            "63 torch.Size([256, 1, 28, 28])\n",
            "64 torch.Size([256, 1, 28, 28])\n",
            "65 torch.Size([256, 1, 28, 28])\n",
            "66 torch.Size([256, 1, 28, 28])\n",
            "67 torch.Size([256, 1, 28, 28])\n",
            "68 torch.Size([256, 1, 28, 28])\n",
            "69 torch.Size([256, 1, 28, 28])\n",
            "70 torch.Size([256, 1, 28, 28])\n",
            "71 torch.Size([256, 1, 28, 28])\n",
            "72 torch.Size([256, 1, 28, 28])\n",
            "73 torch.Size([256, 1, 28, 28])\n",
            "74 torch.Size([256, 1, 28, 28])\n",
            "75 torch.Size([256, 1, 28, 28])\n",
            "76 torch.Size([256, 1, 28, 28])\n",
            "77 torch.Size([256, 1, 28, 28])\n",
            "78 torch.Size([256, 1, 28, 28])\n",
            "79 torch.Size([256, 1, 28, 28])\n",
            "80 torch.Size([256, 1, 28, 28])\n",
            "81 torch.Size([256, 1, 28, 28])\n",
            "82 torch.Size([256, 1, 28, 28])\n",
            "83 torch.Size([256, 1, 28, 28])\n",
            "84 torch.Size([256, 1, 28, 28])\n",
            "85 torch.Size([256, 1, 28, 28])\n",
            "86 torch.Size([256, 1, 28, 28])\n",
            "87 torch.Size([256, 1, 28, 28])\n",
            "88 torch.Size([256, 1, 28, 28])\n",
            "89 torch.Size([256, 1, 28, 28])\n",
            "90 torch.Size([256, 1, 28, 28])\n",
            "91 torch.Size([256, 1, 28, 28])\n",
            "92 torch.Size([256, 1, 28, 28])\n",
            "93 torch.Size([256, 1, 28, 28])\n",
            "94 torch.Size([256, 1, 28, 28])\n",
            "95 torch.Size([256, 1, 28, 28])\n",
            "96 torch.Size([256, 1, 28, 28])\n",
            "97 torch.Size([256, 1, 28, 28])\n",
            "98 torch.Size([256, 1, 28, 28])\n",
            "99 torch.Size([256, 1, 28, 28])\n",
            "100 torch.Size([256, 1, 28, 28])\n",
            "101 torch.Size([256, 1, 28, 28])\n",
            "102 torch.Size([256, 1, 28, 28])\n",
            "103 torch.Size([256, 1, 28, 28])\n",
            "104 torch.Size([256, 1, 28, 28])\n",
            "105 torch.Size([256, 1, 28, 28])\n",
            "106 torch.Size([256, 1, 28, 28])\n",
            "107 torch.Size([256, 1, 28, 28])\n",
            "108 torch.Size([256, 1, 28, 28])\n",
            "109 torch.Size([256, 1, 28, 28])\n",
            "110 torch.Size([256, 1, 28, 28])\n",
            "111 torch.Size([256, 1, 28, 28])\n",
            "112 torch.Size([256, 1, 28, 28])\n",
            "113 torch.Size([256, 1, 28, 28])\n",
            "114 torch.Size([256, 1, 28, 28])\n",
            "115 torch.Size([256, 1, 28, 28])\n",
            "116 torch.Size([256, 1, 28, 28])\n",
            "117 torch.Size([256, 1, 28, 28])\n",
            "118 torch.Size([256, 1, 28, 28])\n",
            "119 torch.Size([256, 1, 28, 28])\n",
            "120 torch.Size([256, 1, 28, 28])\n",
            "121 torch.Size([256, 1, 28, 28])\n",
            "122 torch.Size([256, 1, 28, 28])\n",
            "123 torch.Size([256, 1, 28, 28])\n",
            "124 torch.Size([256, 1, 28, 28])\n",
            "125 torch.Size([256, 1, 28, 28])\n",
            "126 torch.Size([256, 1, 28, 28])\n",
            "127 torch.Size([256, 1, 28, 28])\n",
            "128 torch.Size([256, 1, 28, 28])\n",
            "129 torch.Size([256, 1, 28, 28])\n",
            "130 torch.Size([256, 1, 28, 28])\n",
            "131 torch.Size([256, 1, 28, 28])\n",
            "132 torch.Size([256, 1, 28, 28])\n",
            "133 torch.Size([256, 1, 28, 28])\n",
            "134 torch.Size([256, 1, 28, 28])\n",
            "135 torch.Size([256, 1, 28, 28])\n",
            "136 torch.Size([256, 1, 28, 28])\n",
            "137 torch.Size([256, 1, 28, 28])\n",
            "138 torch.Size([256, 1, 28, 28])\n",
            "139 torch.Size([256, 1, 28, 28])\n",
            "140 torch.Size([256, 1, 28, 28])\n",
            "141 torch.Size([256, 1, 28, 28])\n",
            "142 torch.Size([256, 1, 28, 28])\n",
            "143 torch.Size([256, 1, 28, 28])\n",
            "144 torch.Size([256, 1, 28, 28])\n",
            "145 torch.Size([256, 1, 28, 28])\n",
            "146 torch.Size([256, 1, 28, 28])\n",
            "147 torch.Size([256, 1, 28, 28])\n",
            "148 torch.Size([256, 1, 28, 28])\n",
            "149 torch.Size([256, 1, 28, 28])\n",
            "150 torch.Size([256, 1, 28, 28])\n",
            "151 torch.Size([256, 1, 28, 28])\n",
            "152 torch.Size([256, 1, 28, 28])\n",
            "153 torch.Size([256, 1, 28, 28])\n",
            "154 torch.Size([256, 1, 28, 28])\n",
            "155 torch.Size([256, 1, 28, 28])\n",
            "156 torch.Size([256, 1, 28, 28])\n",
            "157 torch.Size([256, 1, 28, 28])\n",
            "158 torch.Size([256, 1, 28, 28])\n",
            "159 torch.Size([256, 1, 28, 28])\n",
            "160 torch.Size([256, 1, 28, 28])\n",
            "161 torch.Size([256, 1, 28, 28])\n",
            "162 torch.Size([256, 1, 28, 28])\n",
            "163 torch.Size([256, 1, 28, 28])\n",
            "164 torch.Size([256, 1, 28, 28])\n",
            "165 torch.Size([256, 1, 28, 28])\n",
            "166 torch.Size([256, 1, 28, 28])\n",
            "167 torch.Size([256, 1, 28, 28])\n",
            "168 torch.Size([256, 1, 28, 28])\n",
            "169 torch.Size([256, 1, 28, 28])\n",
            "170 torch.Size([256, 1, 28, 28])\n",
            "171 torch.Size([256, 1, 28, 28])\n",
            "172 torch.Size([256, 1, 28, 28])\n",
            "173 torch.Size([256, 1, 28, 28])\n",
            "174 torch.Size([256, 1, 28, 28])\n",
            "175 torch.Size([256, 1, 28, 28])\n",
            "176 torch.Size([256, 1, 28, 28])\n",
            "177 torch.Size([256, 1, 28, 28])\n",
            "178 torch.Size([256, 1, 28, 28])\n",
            "179 torch.Size([256, 1, 28, 28])\n",
            "180 torch.Size([256, 1, 28, 28])\n",
            "181 torch.Size([256, 1, 28, 28])\n",
            "182 torch.Size([256, 1, 28, 28])\n",
            "183 torch.Size([256, 1, 28, 28])\n",
            "184 torch.Size([256, 1, 28, 28])\n",
            "185 torch.Size([256, 1, 28, 28])\n",
            "186 torch.Size([256, 1, 28, 28])\n",
            "187 torch.Size([256, 1, 28, 28])\n",
            "188 torch.Size([256, 1, 28, 28])\n",
            "189 torch.Size([256, 1, 28, 28])\n",
            "190 torch.Size([256, 1, 28, 28])\n",
            "191 torch.Size([256, 1, 28, 28])\n",
            "192 torch.Size([256, 1, 28, 28])\n",
            "193 torch.Size([256, 1, 28, 28])\n",
            "194 torch.Size([256, 1, 28, 28])\n",
            "195 torch.Size([256, 1, 28, 28])\n",
            "196 torch.Size([256, 1, 28, 28])\n",
            "197 torch.Size([256, 1, 28, 28])\n",
            "198 torch.Size([256, 1, 28, 28])\n",
            "199 torch.Size([256, 1, 28, 28])\n",
            "200 torch.Size([256, 1, 28, 28])\n",
            "201 torch.Size([256, 1, 28, 28])\n",
            "202 torch.Size([256, 1, 28, 28])\n",
            "203 torch.Size([256, 1, 28, 28])\n",
            "204 torch.Size([256, 1, 28, 28])\n",
            "205 torch.Size([256, 1, 28, 28])\n",
            "206 torch.Size([256, 1, 28, 28])\n",
            "207 torch.Size([256, 1, 28, 28])\n",
            "208 torch.Size([256, 1, 28, 28])\n",
            "209 torch.Size([256, 1, 28, 28])\n",
            "210 torch.Size([256, 1, 28, 28])\n",
            "211 torch.Size([256, 1, 28, 28])\n",
            "212 torch.Size([256, 1, 28, 28])\n",
            "213 torch.Size([256, 1, 28, 28])\n",
            "214 torch.Size([256, 1, 28, 28])\n",
            "215 torch.Size([256, 1, 28, 28])\n",
            "216 torch.Size([256, 1, 28, 28])\n",
            "217 torch.Size([256, 1, 28, 28])\n",
            "218 torch.Size([256, 1, 28, 28])\n",
            "219 torch.Size([256, 1, 28, 28])\n",
            "220 torch.Size([256, 1, 28, 28])\n",
            "221 torch.Size([256, 1, 28, 28])\n",
            "222 torch.Size([256, 1, 28, 28])\n",
            "223 torch.Size([256, 1, 28, 28])\n",
            "224 torch.Size([256, 1, 28, 28])\n",
            "225 torch.Size([256, 1, 28, 28])\n",
            "226 torch.Size([256, 1, 28, 28])\n",
            "227 torch.Size([256, 1, 28, 28])\n",
            "228 torch.Size([256, 1, 28, 28])\n",
            "229 torch.Size([256, 1, 28, 28])\n",
            "230 torch.Size([256, 1, 28, 28])\n",
            "231 torch.Size([256, 1, 28, 28])\n",
            "232 torch.Size([256, 1, 28, 28])\n",
            "233 torch.Size([256, 1, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pD6nus9C8t7p"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gC-4V67-88YK"
      },
      "source": [
        "# nn.Sequential(nn.Conv2d(1, 32, 3), \n",
        "#               nn.ReLU(),\n",
        "#               nn.MaxPool2d(3,2),\n",
        "#               nn.Conv2d(32, 64, 3),\n",
        "#               nn.ReLU(),\n",
        "#               nn.MaxPool2d(3,2),\n",
        "#               nn.Linear(64*7*7, 1024),\n",
        "#               nn.Linear(1024,10)\n",
        "#           )"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ske5P4vXEvm1"
      },
      "source": [
        "#or \n",
        "class convnet(nn.Module):\n",
        "  def __init__(self,num_class):\n",
        "    super(convnet,self).__init__()  #do not forget \n",
        "    # Layer 1\n",
        "    self.conv1=nn.Sequential(nn.Conv2d(1, 32, 3), \n",
        "              nn.ReLU(),\n",
        "              nn.MaxPool2d(3,2))\n",
        "    #or\n",
        "   # self.conv2d_1=nn.Conv2d(1,32,(3,3))  #size of image is 28*28\n",
        "   # self.reu_1=nn.ReLU()\n",
        "   # self.maxpool_1=nn.MaxPool2d(3,2)     #after maxpooling, size of image is 14*14\n",
        "    # Layer 2\n",
        "    self.conv2d_2=nn.Conv2d(32,64,(3,3))  #64 channels\n",
        "    self.relu_2=nn.ReLU()\n",
        "    self.maxpool_2=nn.MaxPool2d(3,2)    # kernel, stride, 64 * 7*7 is size of output of Layer 2\n",
        "    # Layer 3\n",
        "    self.fc1= nn.Linear(64*7*7, 1024)\n",
        "    self.fc2= nn.Linear(1024, num_class)  #10 in num of classes\n",
        "\n",
        "  def forward(self, x):\n",
        "     #Layer 1\n",
        "     y= self.conv2d_1(x)\n",
        "     y=self.relu(y)\n",
        "     y=self.maxpool_1(y)\n",
        "     #Layer 2\n",
        "     y=self.conv2d_2(y)\n",
        "     y=self.relu_2(y)\n",
        "     y=self.maxpool(y)\n",
        "     #Layer 3\n",
        "     y= y.view(y.size(0),1)  # convert 64*7*7 to a vector\n",
        "     y= self.fc1(y)\n",
        "     y= self.fc2(y)\n",
        "            \n",
        "     return y\n",
        "\n"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VF7fPfqIJUhN"
      },
      "source": [
        "\n",
        "# # different Example with skipe connections\n",
        "# class convnet(nn.Module):\n",
        "#   def __init__(self):\n",
        "#     super(convnet,self).__init__()  #do not forget \n",
        "#     # Layer 1\n",
        "#     self.conv1=nn.Sequential(nn.Conv2d(1, 32, 3), \n",
        "#               nn.ReLU(),\n",
        "#               nn.MaxPool2d(3,1))  #stride is 1, no dimention reduction\n",
        "#     # Layer 2    \n",
        "#     self.conv2=nn.Sequential(nn.Conv2d(32, 32, 3), \n",
        "#               nn.ReLU(),\n",
        "#               nn.MaxPool2d(3,1))  #stride is 1, no dimention reduction\n",
        " \n",
        "#     # Layer 2\n",
        "#     self.conv2d_2=nn.Conv2d(32,64,(3,3))  #64 channels\n",
        "#     self.relu_2=nn.ReLU()\n",
        "#     self.maxpool_2=nn.MaxPool2d(3,2)    # kernel, stride, 64 * 7*7 is size of output of Layer 2\n",
        "#     # Layer 3\n",
        "#     self.fc1= nn.Linear(64*7*7, 1024)\n",
        "#     self.fc2= nn.Linear(1024, 10)  #10 in num of classes\n",
        "\n",
        "#   def forward(self, x):\n",
        "#      #Layer 1\n",
        "#      y= self.conv1(x)\n",
        "#      y= self.conv2(y)+y #it uses output of previous step\n",
        "#      #Layer 2\n",
        "#      y=self.conv2d_2(y)\n",
        "#      y=self.relu_2(y)\n",
        "#      y=self.maxpool(y)\n",
        "#      #Layer 3\n",
        "#      y= y.view(y.size(0),1)  # convert 64*7*7 to a vector\n",
        "#      y= self.fc1(y)\n",
        "#      y= self.fc2(y)\n",
        "            \n",
        "#      return y"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jx2CEgOOUyO"
      },
      "source": [
        "# # different Example with functional \n",
        "# class convnet(nn.Module):\n",
        "#   def __init__(self):\n",
        "#     super(convnet,self).__init__()  #do not forget \n",
        "#     # Layer 1\n",
        "#     self.conv1=nn.Sequential(nn.Conv2d(1, 32, 3), \n",
        "#               nn.ReLU(),\n",
        "#               nn.MaxPool2d(3,1))  #stride is 1, no dimention reduction\n",
        "#     # Layer 2    \n",
        "#     #self.conv2=nn.Sequential(nn.Conv2d(32, 32, 3), \n",
        "#     #         nn.ReLU(),\n",
        "#     #        nn.MaxPool2d(3,1))  #stride is 1, no dimention reduction\n",
        " \n",
        "#     # Layer 2\n",
        "#     self.conv2d_2=nn.Conv2d(32,64,(3,3))  #64 channels\n",
        "#     self.relu_2=nn.ReLU()\n",
        "#     self.maxpool_2=nn.MaxPool2d(3,2)    # kernel, stride, 64 * 7*7 is size of output of Layer 2\n",
        "#     # Layer 3\n",
        "#     self.fc1= nn.Linear(64*7*7, 1024)\n",
        "#     self.fc2= nn.Linear(1024, 10)  #10 in num of classes\n",
        "\n",
        "#   def forward(self, x):\n",
        "#      #Layer 1\n",
        "#      #y= self.conv1(x)\n",
        "#      y=torch.nn.functional.max_pool2d(self.conv1(x)) #no need to define max pool and relu in the init\n",
        "#      #y= self.conv2(y)+y #it uses output of previous step\n",
        "#      #Layer 2\n",
        "#      y=self.conv2d_2(y)\n",
        "#      y=self.relu_2(y)\n",
        "#      y=self.maxpool(y)\n",
        "#      #Layer 3\n",
        "#      y= y.view(y.size(0),1)  # convert 64*7*7 to a vector\n",
        "#      y= self.fc1(y)\n",
        "#      y= self.fc2(y)\n",
        "            \n",
        "#      return y"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djP2yCCpIWLF",
        "outputId": "3fa4c61a-64cc-4252-9224-f8abf08a5cb7"
      },
      "source": [
        "model=convnet(num_class).to(device) #take model to GPU\n",
        "print(model)"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "convnet(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv2d_2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (relu_2): ReLU()\n",
            "  (maxpool_2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=3136, out_features=1024, bias=True)\n",
            "  (fc2): Linear(in_features=1024, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jdPKdv-QeA1",
        "outputId": "4e2e53b7-b262-4755-ed6e-60f0b1201ae4"
      },
      "source": [
        "print(model.conv1)\n",
        "print(model.conv1[2])\n",
        "#model.conv1[0].weight\n",
        "#model.conv1[0].bias\n"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (1): ReLU()\n",
            "  (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            ")\n",
            "MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGT8GDsBUuAB"
      },
      "source": [
        "# Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "id": "1xz3qG1cUz6y",
        "outputId": "37b61024-a634-4113-e94e-d526cab0cac1"
      },
      "source": [
        "criterion=nn.CrossEntropyLoss()\n",
        "optimizer=optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-153-8aa629c6b4f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'optim' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hi3oG_TuVfL7"
      },
      "source": [
        "#https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html\n",
        "#trainer\n",
        "\n",
        "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    val_acc_history = []\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # Get model outputs and calculate loss\n",
        "                    # Special case for inception because in training it has an auxiliary output. In train\n",
        "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
        "                    #   but in testing we only consider the final output.\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            if phase == 'val':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, val_acc_history\n",
        "\n",
        "\n",
        "\n",
        "    model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)"
      ],
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnsA-L2-hD46"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4kq3BQBgxdR",
        "outputId": "378c7505-af29-47fc-b17d-acb4918b14d8"
      },
      "source": [
        "{'train':1,'test':2}"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test': 2, 'train': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "i4_JM-Y3hFb3",
        "outputId": "082ef550-a66c-4ac8-bfbe-1a0b50d79222"
      },
      "source": [
        "# Plot the training curves of validation accuracy vs. number\n",
        "#  of training epochs for the transfer learning method and\n",
        "#  the model trained from scratch\n",
        "ohist = []\n",
        "shist = []\n",
        "\n",
        "ohist = [h.cpu().numpy() for h in hist]\n",
        "shist = [h.cpu().numpy() for h in scratch_hist]\n",
        "\n",
        "plt.title(\"Validation Accuracy vs. Number of Training Epochs\")\n",
        "plt.xlabel(\"Training Epochs\")\n",
        "plt.ylabel(\"Validation Accuracy\")\n",
        "plt.plot(range(1,num_epochs+1),ohist,label=\"Pretrained\")\n",
        "plt.plot(range(1,num_epochs+1),shist,label=\"Scratch\")\n",
        "plt.ylim((0,1.))\n",
        "plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-158-f372db94a454>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mshist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mohist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mshist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscratch_hist\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'hist' is not defined"
          ]
        }
      ]
    }
  ]
}